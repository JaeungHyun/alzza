{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pulsar_dataset(adjust_ratio):\n",
    "    df = pd.read_csv('data/chap02/pulsar_stars.csv')\n",
    "    pulsars = np.asarray(df[df['target_class'] == 1])\n",
    "    stars = np.asarray(df[df['target_class'] == 0])\n",
    "\n",
    "    input_cnt, output_cnt = 8, 1\n",
    "\n",
    "    star_cnt, pulsar_cnt = len(stars), len(pulsars)\n",
    "    if adjust_ratio:\n",
    "        data = np.zeros([2 * star_cnt, 9])\n",
    "        data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
    "        for n in range(star_cnt):\n",
    "            data[star_cnt + n] = np.asarray(pulsars[n % pulsar_cnt], dtype='float32')\n",
    "    else:\n",
    "        data = np.zeros([star_cnt + pulsar_cnt, 9])\n",
    "        data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
    "        data[star_cnt:, :] = np.asarray(pulsars, dtype='float32')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pulsar_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32518, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[:,:-1], data[:,-1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "train_loader = DataLoader(trn, batch_size = 512, shuffle=True)\n",
    "\n",
    "trn = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "test_loader = DataLoader(trn, batch_size = 512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.linear_1 = torch.nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        linear1 = self.linear_1(input_tensor)\n",
    "        out = torch.sigmoid(linear1)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Training on {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model        = NeuralNet(8, 1).to(DEVICE)\n",
    "optimizer    = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion    = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# ## 테스트하기\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            # 배치 오차를 합산\n",
    "            test_loss += criterion(output.squeeze(), target).item()\n",
    "\n",
    "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/26014 (0%)]\tLoss: 8.204283\n",
      "Train Epoch: 1 [5120/26014 (20%)]\tLoss: 2.637599\n",
      "Train Epoch: 1 [10240/26014 (39%)]\tLoss: 11.965713\n",
      "Train Epoch: 1 [15360/26014 (59%)]\tLoss: 1.930734\n",
      "Train Epoch: 1 [20480/26014 (78%)]\tLoss: 1.690676\n",
      "Train Epoch: 1 [20700/26014 (98%)]\tLoss: 1.609246\n",
      "[1] Test Loss: 0.0037, Accuracy: 51.11%\n",
      "Train Epoch: 2 [0/26014 (0%)]\tLoss: 1.412377\n",
      "Train Epoch: 2 [5120/26014 (20%)]\tLoss: 1.439458\n",
      "Train Epoch: 2 [10240/26014 (39%)]\tLoss: 3.086080\n",
      "Train Epoch: 2 [15360/26014 (59%)]\tLoss: 5.236709\n",
      "Train Epoch: 2 [20480/26014 (78%)]\tLoss: 1.807706\n",
      "Train Epoch: 2 [20700/26014 (98%)]\tLoss: 1.796612\n",
      "[2] Test Loss: 0.0030, Accuracy: 51.11%\n",
      "Train Epoch: 3 [0/26014 (0%)]\tLoss: 1.547927\n",
      "Train Epoch: 3 [5120/26014 (20%)]\tLoss: 4.394727\n",
      "Train Epoch: 3 [10240/26014 (39%)]\tLoss: 1.521451\n",
      "Train Epoch: 3 [15360/26014 (59%)]\tLoss: 1.367234\n",
      "Train Epoch: 3 [20480/26014 (78%)]\tLoss: 1.336256\n",
      "Train Epoch: 3 [20700/26014 (98%)]\tLoss: 0.968271\n",
      "[3] Test Loss: 0.0014, Accuracy: 51.11%\n",
      "Train Epoch: 4 [0/26014 (0%)]\tLoss: 0.759313\n",
      "Train Epoch: 4 [5120/26014 (20%)]\tLoss: 1.210784\n",
      "Train Epoch: 4 [10240/26014 (39%)]\tLoss: 0.815102\n",
      "Train Epoch: 4 [15360/26014 (59%)]\tLoss: 2.304481\n",
      "Train Epoch: 4 [20480/26014 (78%)]\tLoss: 0.490016\n",
      "Train Epoch: 4 [20700/26014 (98%)]\tLoss: 2.143588\n",
      "[4] Test Loss: 0.0172, Accuracy: 51.11%\n",
      "Train Epoch: 5 [0/26014 (0%)]\tLoss: 9.492193\n",
      "Train Epoch: 5 [5120/26014 (20%)]\tLoss: 2.256226\n",
      "Train Epoch: 5 [10240/26014 (39%)]\tLoss: 0.790074\n",
      "Train Epoch: 5 [15360/26014 (59%)]\tLoss: 1.552791\n",
      "Train Epoch: 5 [20480/26014 (78%)]\tLoss: 0.707852\n",
      "Train Epoch: 5 [20700/26014 (98%)]\tLoss: 2.605775\n",
      "[5] Test Loss: 0.0164, Accuracy: 51.11%\n",
      "Train Epoch: 6 [0/26014 (0%)]\tLoss: 7.739184\n",
      "Train Epoch: 6 [5120/26014 (20%)]\tLoss: 0.967934\n",
      "Train Epoch: 6 [10240/26014 (39%)]\tLoss: 1.730853\n",
      "Train Epoch: 6 [15360/26014 (59%)]\tLoss: 3.147432\n",
      "Train Epoch: 6 [20480/26014 (78%)]\tLoss: 5.185526\n",
      "Train Epoch: 6 [20700/26014 (98%)]\tLoss: 1.015156\n",
      "[6] Test Loss: 0.0016, Accuracy: 51.11%\n",
      "Train Epoch: 7 [0/26014 (0%)]\tLoss: 0.836314\n",
      "Train Epoch: 7 [5120/26014 (20%)]\tLoss: 1.195159\n",
      "Train Epoch: 7 [10240/26014 (39%)]\tLoss: 1.862785\n",
      "Train Epoch: 7 [15360/26014 (59%)]\tLoss: 0.763107\n",
      "Train Epoch: 7 [20480/26014 (78%)]\tLoss: 1.226383\n",
      "Train Epoch: 7 [20700/26014 (98%)]\tLoss: 2.269609\n",
      "[7] Test Loss: 0.0025, Accuracy: 51.11%\n",
      "Train Epoch: 8 [0/26014 (0%)]\tLoss: 1.805447\n",
      "Train Epoch: 8 [5120/26014 (20%)]\tLoss: 0.464341\n",
      "Train Epoch: 8 [10240/26014 (39%)]\tLoss: 0.536941\n",
      "Train Epoch: 8 [15360/26014 (59%)]\tLoss: 1.317978\n",
      "Train Epoch: 8 [20480/26014 (78%)]\tLoss: 2.537764\n",
      "Train Epoch: 8 [20700/26014 (98%)]\tLoss: 1.133706\n",
      "[8] Test Loss: 0.0018, Accuracy: 51.11%\n",
      "Train Epoch: 9 [0/26014 (0%)]\tLoss: 0.752835\n",
      "Train Epoch: 9 [5120/26014 (20%)]\tLoss: 5.865211\n",
      "Train Epoch: 9 [10240/26014 (39%)]\tLoss: 0.405707\n",
      "Train Epoch: 9 [15360/26014 (59%)]\tLoss: 1.393192\n",
      "Train Epoch: 9 [20480/26014 (78%)]\tLoss: 0.904516\n",
      "Train Epoch: 9 [20700/26014 (98%)]\tLoss: 1.627566\n",
      "[9] Test Loss: 0.0025, Accuracy: 51.11%\n",
      "Train Epoch: 10 [0/26014 (0%)]\tLoss: 1.396498\n",
      "Train Epoch: 10 [5120/26014 (20%)]\tLoss: 1.232318\n",
      "Train Epoch: 10 [10240/26014 (39%)]\tLoss: 0.776027\n",
      "Train Epoch: 10 [15360/26014 (59%)]\tLoss: 2.551455\n",
      "Train Epoch: 10 [20480/26014 (78%)]\tLoss: 0.647488\n",
      "Train Epoch: 10 [20700/26014 (98%)]\tLoss: 0.532606\n",
      "[10] Test Loss: 0.0011, Accuracy: 51.11%\n",
      "Train Epoch: 11 [0/26014 (0%)]\tLoss: 0.604737\n",
      "Train Epoch: 11 [5120/26014 (20%)]\tLoss: 1.135274\n",
      "Train Epoch: 11 [10240/26014 (39%)]\tLoss: 1.430622\n",
      "Train Epoch: 11 [15360/26014 (59%)]\tLoss: 0.327016\n",
      "Train Epoch: 11 [20480/26014 (78%)]\tLoss: 0.709271\n",
      "Train Epoch: 11 [20700/26014 (98%)]\tLoss: 1.689123\n",
      "[11] Test Loss: 0.0027, Accuracy: 51.11%\n",
      "Train Epoch: 12 [0/26014 (0%)]\tLoss: 1.320881\n",
      "Train Epoch: 12 [5120/26014 (20%)]\tLoss: 0.627063\n",
      "Train Epoch: 12 [10240/26014 (39%)]\tLoss: 0.991081\n",
      "Train Epoch: 12 [15360/26014 (59%)]\tLoss: 2.265781\n",
      "Train Epoch: 12 [20480/26014 (78%)]\tLoss: 1.169216\n",
      "Train Epoch: 12 [20700/26014 (98%)]\tLoss: 2.442823\n",
      "[12] Test Loss: 0.0017, Accuracy: 51.11%\n",
      "Train Epoch: 13 [0/26014 (0%)]\tLoss: 0.905766\n",
      "Train Epoch: 13 [5120/26014 (20%)]\tLoss: 1.388137\n",
      "Train Epoch: 13 [10240/26014 (39%)]\tLoss: 0.890013\n",
      "Train Epoch: 13 [15360/26014 (59%)]\tLoss: 0.487605\n",
      "Train Epoch: 13 [20480/26014 (78%)]\tLoss: 0.931517\n",
      "Train Epoch: 13 [20700/26014 (98%)]\tLoss: 0.767679\n",
      "[13] Test Loss: 0.0057, Accuracy: 51.11%\n",
      "Train Epoch: 14 [0/26014 (0%)]\tLoss: 2.817223\n",
      "Train Epoch: 14 [5120/26014 (20%)]\tLoss: 2.218692\n",
      "Train Epoch: 14 [10240/26014 (39%)]\tLoss: 1.430664\n",
      "Train Epoch: 14 [15360/26014 (59%)]\tLoss: 7.101638\n",
      "Train Epoch: 14 [20480/26014 (78%)]\tLoss: 0.429729\n",
      "Train Epoch: 14 [20700/26014 (98%)]\tLoss: 0.551480\n",
      "[14] Test Loss: 0.0010, Accuracy: 51.11%\n",
      "Train Epoch: 15 [0/26014 (0%)]\tLoss: 0.503791\n",
      "Train Epoch: 15 [5120/26014 (20%)]\tLoss: 0.949956\n",
      "Train Epoch: 15 [10240/26014 (39%)]\tLoss: 0.896018\n",
      "Train Epoch: 15 [15360/26014 (59%)]\tLoss: 2.507270\n",
      "Train Epoch: 15 [20480/26014 (78%)]\tLoss: 0.843543\n",
      "Train Epoch: 15 [20700/26014 (98%)]\tLoss: 0.936464\n",
      "[15] Test Loss: 0.0063, Accuracy: 51.11%\n",
      "Train Epoch: 16 [0/26014 (0%)]\tLoss: 3.204523\n",
      "Train Epoch: 16 [5120/26014 (20%)]\tLoss: 0.551788\n",
      "Train Epoch: 16 [10240/26014 (39%)]\tLoss: 3.752334\n",
      "Train Epoch: 16 [15360/26014 (59%)]\tLoss: 3.015904\n",
      "Train Epoch: 16 [20480/26014 (78%)]\tLoss: 1.465288\n",
      "Train Epoch: 16 [20700/26014 (98%)]\tLoss: 1.411092\n",
      "[16] Test Loss: 0.0023, Accuracy: 51.11%\n",
      "Train Epoch: 17 [0/26014 (0%)]\tLoss: 1.501341\n",
      "Train Epoch: 17 [5120/26014 (20%)]\tLoss: 3.257873\n",
      "Train Epoch: 17 [10240/26014 (39%)]\tLoss: 0.475474\n",
      "Train Epoch: 17 [15360/26014 (59%)]\tLoss: 1.012518\n",
      "Train Epoch: 17 [20480/26014 (78%)]\tLoss: 0.606510\n",
      "Train Epoch: 17 [20700/26014 (98%)]\tLoss: 0.648844\n",
      "[17] Test Loss: 0.0010, Accuracy: 51.11%\n",
      "Train Epoch: 18 [0/26014 (0%)]\tLoss: 0.665198\n",
      "Train Epoch: 18 [5120/26014 (20%)]\tLoss: 1.284337\n",
      "Train Epoch: 18 [10240/26014 (39%)]\tLoss: 1.035638\n",
      "Train Epoch: 18 [15360/26014 (59%)]\tLoss: 0.735496\n",
      "Train Epoch: 18 [20480/26014 (78%)]\tLoss: 3.127151\n",
      "Train Epoch: 18 [20700/26014 (98%)]\tLoss: 1.740601\n",
      "[18] Test Loss: 0.0021, Accuracy: 51.11%\n",
      "Train Epoch: 19 [0/26014 (0%)]\tLoss: 0.997118\n",
      "Train Epoch: 19 [5120/26014 (20%)]\tLoss: 1.826699\n",
      "Train Epoch: 19 [10240/26014 (39%)]\tLoss: 0.855703\n",
      "Train Epoch: 19 [15360/26014 (59%)]\tLoss: 1.022711\n",
      "Train Epoch: 19 [20480/26014 (78%)]\tLoss: 0.601771\n",
      "Train Epoch: 19 [20700/26014 (98%)]\tLoss: 0.617721\n",
      "[19] Test Loss: 0.0009, Accuracy: 51.11%\n",
      "Train Epoch: 20 [0/26014 (0%)]\tLoss: 0.646729\n",
      "Train Epoch: 20 [5120/26014 (20%)]\tLoss: 0.573696\n",
      "Train Epoch: 20 [10240/26014 (39%)]\tLoss: 2.685237\n",
      "Train Epoch: 20 [15360/26014 (59%)]\tLoss: 2.286807\n",
      "Train Epoch: 20 [20480/26014 (78%)]\tLoss: 0.615124\n",
      "Train Epoch: 20 [20700/26014 (98%)]\tLoss: 1.981498\n",
      "[20] Test Loss: 0.0035, Accuracy: 51.11%\n",
      "Train Epoch: 21 [0/26014 (0%)]\tLoss: 2.093060\n",
      "Train Epoch: 21 [5120/26014 (20%)]\tLoss: 0.750321\n",
      "Train Epoch: 21 [10240/26014 (39%)]\tLoss: 1.251190\n",
      "Train Epoch: 21 [15360/26014 (59%)]\tLoss: 1.120893\n",
      "Train Epoch: 21 [20480/26014 (78%)]\tLoss: 1.194029\n",
      "Train Epoch: 21 [20700/26014 (98%)]\tLoss: 1.349356\n",
      "[21] Test Loss: 0.0020, Accuracy: 51.11%\n",
      "Train Epoch: 22 [0/26014 (0%)]\tLoss: 0.873369\n",
      "Train Epoch: 22 [5120/26014 (20%)]\tLoss: 3.011191\n",
      "Train Epoch: 22 [10240/26014 (39%)]\tLoss: 0.463167\n",
      "Train Epoch: 22 [15360/26014 (59%)]\tLoss: 1.651686\n",
      "Train Epoch: 22 [20480/26014 (78%)]\tLoss: 0.808582\n",
      "Train Epoch: 22 [20700/26014 (98%)]\tLoss: 1.438311\n",
      "[22] Test Loss: 0.0035, Accuracy: 51.11%\n",
      "Train Epoch: 23 [0/26014 (0%)]\tLoss: 1.175443\n",
      "Train Epoch: 23 [5120/26014 (20%)]\tLoss: 3.005456\n",
      "Train Epoch: 23 [10240/26014 (39%)]\tLoss: 1.041054\n",
      "Train Epoch: 23 [15360/26014 (59%)]\tLoss: 0.871587\n",
      "Train Epoch: 23 [20480/26014 (78%)]\tLoss: 0.789948\n",
      "Train Epoch: 23 [20700/26014 (98%)]\tLoss: 0.780621\n",
      "[23] Test Loss: 0.0073, Accuracy: 51.11%\n",
      "Train Epoch: 24 [0/26014 (0%)]\tLoss: 3.874817\n",
      "Train Epoch: 24 [5120/26014 (20%)]\tLoss: 0.443281\n",
      "Train Epoch: 24 [10240/26014 (39%)]\tLoss: 0.901441\n",
      "Train Epoch: 24 [15360/26014 (59%)]\tLoss: 0.629451\n",
      "Train Epoch: 24 [20480/26014 (78%)]\tLoss: 0.641926\n",
      "Train Epoch: 24 [20700/26014 (98%)]\tLoss: 1.448511\n",
      "[24] Test Loss: 0.0016, Accuracy: 51.11%\n",
      "Train Epoch: 25 [0/26014 (0%)]\tLoss: 0.928150\n",
      "Train Epoch: 25 [5120/26014 (20%)]\tLoss: 2.340411\n",
      "Train Epoch: 25 [10240/26014 (39%)]\tLoss: 1.211185\n",
      "Train Epoch: 25 [15360/26014 (59%)]\tLoss: 0.506288\n",
      "Train Epoch: 25 [20480/26014 (78%)]\tLoss: 3.908161\n",
      "Train Epoch: 25 [20700/26014 (98%)]\tLoss: 0.373919\n",
      "[25] Test Loss: 0.0009, Accuracy: 51.11%\n",
      "Train Epoch: 26 [0/26014 (0%)]\tLoss: 0.427692\n",
      "Train Epoch: 26 [5120/26014 (20%)]\tLoss: 0.607436\n",
      "Train Epoch: 26 [10240/26014 (39%)]\tLoss: 0.565949\n",
      "Train Epoch: 26 [15360/26014 (59%)]\tLoss: 1.017589\n",
      "Train Epoch: 26 [20480/26014 (78%)]\tLoss: 0.514556\n",
      "Train Epoch: 26 [20700/26014 (98%)]\tLoss: 1.136742\n",
      "[26] Test Loss: 0.0016, Accuracy: 51.11%\n",
      "Train Epoch: 27 [0/26014 (0%)]\tLoss: 0.771364\n",
      "Train Epoch: 27 [5120/26014 (20%)]\tLoss: 0.939026\n",
      "Train Epoch: 27 [10240/26014 (39%)]\tLoss: 0.334488\n",
      "Train Epoch: 27 [15360/26014 (59%)]\tLoss: 0.978102\n",
      "Train Epoch: 27 [20480/26014 (78%)]\tLoss: 0.513538\n",
      "Train Epoch: 27 [20700/26014 (98%)]\tLoss: 4.875800\n",
      "[27] Test Loss: 0.0042, Accuracy: 51.11%\n",
      "Train Epoch: 28 [0/26014 (0%)]\tLoss: 1.997815\n",
      "Train Epoch: 28 [5120/26014 (20%)]\tLoss: 6.762909\n",
      "Train Epoch: 28 [10240/26014 (39%)]\tLoss: 0.814490\n",
      "Train Epoch: 28 [15360/26014 (59%)]\tLoss: 0.892440\n",
      "Train Epoch: 28 [20480/26014 (78%)]\tLoss: 0.536138\n",
      "Train Epoch: 28 [20700/26014 (98%)]\tLoss: 2.019771\n",
      "[28] Test Loss: 0.0019, Accuracy: 51.11%\n",
      "Train Epoch: 29 [0/26014 (0%)]\tLoss: 0.889322\n",
      "Train Epoch: 29 [5120/26014 (20%)]\tLoss: 0.639477\n",
      "Train Epoch: 29 [10240/26014 (39%)]\tLoss: 1.799292\n",
      "Train Epoch: 29 [15360/26014 (59%)]\tLoss: 0.566472\n",
      "Train Epoch: 29 [20480/26014 (78%)]\tLoss: 3.585295\n",
      "Train Epoch: 29 [20700/26014 (98%)]\tLoss: 0.693812\n",
      "[29] Test Loss: 0.0011, Accuracy: 51.11%\n",
      "Train Epoch: 30 [0/26014 (0%)]\tLoss: 0.421845\n",
      "Train Epoch: 30 [5120/26014 (20%)]\tLoss: 0.772779\n",
      "Train Epoch: 30 [10240/26014 (39%)]\tLoss: 0.468925\n",
      "Train Epoch: 30 [15360/26014 (59%)]\tLoss: 1.257183\n",
      "Train Epoch: 30 [20480/26014 (78%)]\tLoss: 3.400499\n",
      "Train Epoch: 30 [20700/26014 (98%)]\tLoss: 0.973774\n",
      "[30] Test Loss: 0.0015, Accuracy: 51.11%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
