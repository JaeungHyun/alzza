{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../chap09/cnn_ext_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnBasicModel(CnnExtModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_basic_alloc_rnn_layer(self, input_shape, hconfig):\n",
    "    inseq = get_conf_param(hconfig, 'inseq', True)\n",
    "    outseq = get_conf_param(hconfig, 'outseq', True)\n",
    "\n",
    "    if inseq:\n",
    "        timesteps1, timefeats = input_shape\n",
    "    else:\n",
    "        timesteps1 = get_conf_param(hconfig, 'timesteps') + 1\n",
    "        timefeats = np.prod(input_shape)\n",
    "    \n",
    "    recur_size = get_conf_param(hconfig, 'recur_size')\n",
    "\n",
    "    ex_inp_dim = timefeats + recur_size\n",
    "    weight, bias = self.alloc_param_pair([ex_inp_dim, recur_size])\n",
    "\n",
    "    if outseq:\n",
    "        output_shape = [timesteps1, recur_size]\n",
    "    else:\n",
    "        output_shape = [recur_size]\n",
    "    \n",
    "    rnn_info = [inseq, outseq, timesteps1, timefeats, recur_size]\n",
    "    \n",
    "    return {'w':weight, 'b':bias, 'info':rnn_info}, output_shape\n",
    "\n",
    "RnnBasicModel.alloc_rnn_layer = rnn_basic_alloc_rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_basic_forward_rnn_layer(self, x, hconfig, pm):\n",
    "    inseq, outseq, timesteps1, timefeats, recur_size = pm['info']\n",
    "    mb_size = x.shape[0]\n",
    "\n",
    "    if inseq:\n",
    "        x_slices = x[:, 1:, :].transpose([1,0,2])\n",
    "        lengths = x[:, 0, 0].astype(np.int32)\n",
    "        timesteps = np.max(lengths)\n",
    "    else:\n",
    "        x_slice = x\n",
    "        timesteps = timesteps1 - 1\n",
    "        lengths = [timesteps] * mb_size\n",
    "\n",
    "    recurrent = np.zeros([mb_size, recur_size])\n",
    "    outputs, aux_steps = [], []\n",
    "    \n",
    "    for n in range(timesteps):\n",
    "        if inseq: x_slice = x_slices[n]\n",
    "        ex_inp = np.hstack([x_slice, recurrent])\n",
    "\n",
    "\n",
    "        affine = np.matmul(ex_inp, pm['w']) + pm['b']\n",
    "        recurrent = self.activate(affine, hconfig)\n",
    "\n",
    "        outputs.append(recurrent)\n",
    "        aux_steps.append(ex_inp)\n",
    "        \n",
    "    if outseq:\n",
    "        output = np.zeros([mb_size, timesteps1, recur_size])\n",
    "        output[:, 0, 0] = lengths\n",
    "        output[:, 1:, :] = np.asarray(outputs).transpose([1, 0, 2])\n",
    "    else:\n",
    "        output = np.zeros([mb_size, recur_size])\n",
    "        for n in range(mb_size):\n",
    "            output[n] = outputs[lengths[n]-1][n]\n",
    "        \n",
    "    return output, [x, lengths, timesteps, outputs, aux_steps]\n",
    "\n",
    "RnnBasicModel.forward_rnn_layer = rnn_basic_forward_rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_basic_backprop_rnn_layer(self, G_y, hconfig, pm, aux):\n",
    "    inseq, outseq, timesteps1, timefeats, recur_size = pm['info']\n",
    "    x, lengths, timesteps, outputs, aux_steps = aux\n",
    "    mb_size = x.shape[0]\n",
    "\n",
    "    G_weight = np.zeros_like(pm['w'])\n",
    "    G_bias = np.zeros_like(pm['b'])\n",
    "    G_x = np.zeros(x.shape)\n",
    "    G_recurrent = np.zeros([mb_size, recur_size])\n",
    "\n",
    "    if inseq: G_x[:, 0, 0] = lengths\n",
    "\n",
    "    if outseq:\n",
    "        G_outputs = G_y[:, 1:, :].transpose([1, 0, 2])\n",
    "    else:\n",
    "        G_outputs = np.zeros([timesteps, mb_size, recur_size])\n",
    "        for n in range(mb_size):\n",
    "            G_outputs[lengths[n]-1, n, :] = G_y[n]\n",
    "\n",
    "    for n in reversed(range(0, timesteps)):\n",
    "        G_recurrent += G_outputs[n]\n",
    "\n",
    "        ex_inp = aux_steps[n]\n",
    "        \n",
    "        G_affine = self.activate_derv(G_recurrent, outputs[n], hconfig)\n",
    "\n",
    "        g_affine_weight = ex_inp.transpose()\n",
    "        g_affine_input = pm['w'].transpose()\n",
    "    \n",
    "        G_weight += np.matmul(g_affine_weight, G_affine)\n",
    "        G_bias += np.sum(G_affine, axis=0)\n",
    "        G_ex_inp = np.matmul(G_affine, g_affine_input)\n",
    "        \n",
    "        if inseq: G_x[:,n+1,:] = G_ex_inp[:, :timefeats]\n",
    "        else: G_x[:,:] += G_ex_inp[:, :timefeats]\n",
    "            \n",
    "        G_recurrent = G_ex_inp[:, timefeats:]\n",
    "    \n",
    "    self.update_param(pm, 'w', G_weight)\n",
    "    self.update_param(pm, 'b', G_bias)\n",
    "    \n",
    "    return G_x\n",
    "    \n",
    "RnnBasicModel.backprop_rnn_layer = rnn_basic_backprop_rnn_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
