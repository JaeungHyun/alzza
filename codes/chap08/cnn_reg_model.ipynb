{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../chap07/cnn_basic_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnRegModel(CnnBasicModel):\n",
    "    def __init__(self, name, dataset, hconfigs, show_maps=False, \n",
    "                 l2_decay=0, l1_decay=0):\n",
    "        self.l2_decay = l2_decay\n",
    "        self.l1_decay = l1_decay\n",
    "        super(CnnRegModel, self).__init__(name, dataset, hconfigs, show_maps)\n",
    "        \n",
    "    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n",
    "                 report=0, show_cnt=3, show_params=False):\n",
    "        super(CnnRegModel, self).exec_all(epoch_count, batch_size, \n",
    "                                     learning_rate, report, show_cnt)\n",
    "        if show_params: self.show_param_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reg_show_param_dist(self):\n",
    "    params = self.collect_params()\n",
    "    mu = np.mean(params)\n",
    "    sigma = np.sqrt(np.var(params))\n",
    "    plt.hist(params, 100, density=True, facecolor='g', alpha=0.75)\n",
    "    plt.axis([-0.2, 0.2, 0, 20.0])\n",
    "    plt.text(0.08, 15.0, 'mu={:5.3f}'.format(mu))\n",
    "    plt.text(0.08, 13.0, 'sigma={:5.3f}'.format(sigma))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    total_count = len(params)\n",
    "    near_zero_count = len(list(x for x in params if -1e-5 <= x <= 1e-5))\n",
    "    print('Near 0 parameters = {:4.1f}%({}/{})'.\n",
    "        format(near_zero_count/total_count*100, near_zero_count, total_count))\n",
    "\n",
    "def cnn_reg_collect_params(self):\n",
    "    params = list(self.pm_output['w'].flatten())\n",
    "    for pm in self.pm_hiddens:\n",
    "        if 'w' in pm: params += list(pm['w'].flatten())\n",
    "        if 'k' in pm: params += list(pm['k'].flatten())\n",
    "    return params\n",
    "\n",
    "CnnRegModel.show_param_dist = cnn_reg_show_param_dist\n",
    "CnnRegModel.collect_params = cnn_reg_collect_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reg_forward_extra_cost(self, y):\n",
    "    extra, aux_extra = super(CnnRegModel, self).forward_extra_cost(y)\n",
    "    if self.l2_decay > 0 or self.l1_decay > 0:\n",
    "        params = self.collect_params()\n",
    "        if self.l2_decay > 0:\n",
    "            extra += np.sum(np.square(params)) / 2\n",
    "        if self.l1_decay > 0:\n",
    "            extra += np.sum(np.abs(params))\n",
    "    return extra, aux_extra\n",
    "\n",
    "CnnRegModel.forward_extra_cost = cnn_reg_forward_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reg_update_param(self, pm, key, delta):\n",
    "    if self.use_adam:\n",
    "        delta = self.eval_adam_delta(pm, key, delta)\n",
    "\n",
    "    if key in ['w', 'k']:\n",
    "        if self.l2_decay > 0:\n",
    "            delta += self.l2_decay * pm[key] \n",
    "        if self.l1_decay > 0:\n",
    "            delta += self.l1_decay * np.sign(pm[key])\n",
    "\n",
    "    pm[key] -= self.learning_rate * delta\n",
    "        \n",
    "CnnRegModel.update_param = cnn_reg_update_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reg_alloc_dropout_layer(self, input_shape, hconfig):\n",
    "    keep_prob = get_conf_param(hconfig, 'keep_prob', 1.0)\n",
    "    assert keep_prob > 0 and keep_prob <= 1\n",
    "    return {'keep_prob':keep_prob}, input_shape\n",
    "    \n",
    "def cnn_reg_forward_dropout_layer(self, x, hconfig, pm):\n",
    "    if self.is_training:\n",
    "        dmask = np.random.binomial(1, pm['keep_prob'], x.shape)\n",
    "        dropped = x * dmask / pm['keep_prob']\n",
    "        return dropped, dmask\n",
    "    else:\n",
    "        return x, None\n",
    "\n",
    "def cnn_reg_backprop_dropout_layer(self, G_y, hconfig, pm, aux):\n",
    "    dmask = aux\n",
    "    G_hidden = G_y * dmask / pm['keep_prob']\n",
    "    return G_hidden\n",
    "    \n",
    "CnnRegModel.alloc_dropout_layer = cnn_reg_alloc_dropout_layer\n",
    "CnnRegModel.forward_dropout_layer = cnn_reg_forward_dropout_layer\n",
    "CnnRegModel.backprop_dropout_layer = cnn_reg_backprop_dropout_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reg_alloc_noise_layer(self, input_shape, hconfig):\n",
    "    noise_type = get_conf_param(hconfig, 'type', 'normal')\n",
    "    mean = get_conf_param(hconfig, 'mean', 0)\n",
    "    std = get_conf_param(hconfig, 'std', 1.0)\n",
    "    ratio = get_conf_param(hconfig, 'ratio', 1.0)\n",
    "\n",
    "    assert noise_type == 'normal'\n",
    "    \n",
    "    return {'mean':mean, 'std':std, 'ratio':ratio}, input_shape\n",
    "    \n",
    "def cnn_reg_forward_noise_layer(self, x, hconfig, pm):\n",
    "    if self.is_training and np.random.rand() < pm['ratio']:\n",
    "        noise = np.random.normal(pm['mean'], pm['std'], x.shape)\n",
    "        return x + noise, None\n",
    "    else:\n",
    "        return x, None\n",
    "\n",
    "def cnn_reg_backprop_noise_layer(self, G_y, hconfig, pm, aux):\n",
    "    return G_y\n",
    "    \n",
    "CnnRegModel.alloc_noise_layer = cnn_reg_alloc_noise_layer\n",
    "CnnRegModel.forward_noise_layer = cnn_reg_forward_noise_layer\n",
    "CnnRegModel.backprop_noise_layer = cnn_reg_backprop_noise_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_reg_alloc_batch_normal_layer(self, input_shape, hconfig):\n",
    "    pm = {}\n",
    "    rescale = get_conf_param(hconfig, 'rescale', True)\n",
    "    pm['epsilon'] = get_conf_param(hconfig, 'epsilon', 1e-10)\n",
    "    pm['exp_ratio'] = get_conf_param(hconfig, 'exp_ratio', 0.001)\n",
    "    \n",
    "    bn_dim = input_shape[-1]\n",
    "    pm['mavg'] = np.zeros(bn_dim)\n",
    "    pm['mvar'] = np.ones(bn_dim)\n",
    "    if rescale:\n",
    "        pm['scale'] = np.ones(bn_dim)\n",
    "        pm['shift'] = np.zeros(bn_dim)\n",
    "    return pm, input_shape\n",
    "    \n",
    "def cnn_reg_forward_batch_normal_layer(self, x, hconfig, pm):\n",
    "    if self.is_training:\n",
    "        x_flat = x.reshape([-1, x.shape[-1]])\n",
    "        avg = np.mean(x_flat, axis=0)\n",
    "        var = np.var(x_flat, axis=0)\n",
    "        pm['mavg'] += pm['exp_ratio'] * (avg - pm['mavg'])\n",
    "        pm['mvar'] += pm['exp_ratio'] * (var - pm['mvar'])\n",
    "    else:\n",
    "        avg = pm['mavg']\n",
    "        var = pm['mvar']\n",
    "    std = np.sqrt(var + pm['epsilon'])\n",
    "    y = norm_x = (x - avg) / std\n",
    "    if 'scale' in pm:\n",
    "        y = pm['scale'] * norm_x + pm['shift']\n",
    "    return y, [norm_x, std]\n",
    "\n",
    "def cnn_reg_backprop_batch_normal_layer(self, G_y, hconfig, pm, aux):\n",
    "    norm_x, std = aux\n",
    "    if 'scale' in pm:\n",
    "        if len(G_y.shape) == 2: axis = 0\n",
    "        else: axis = (0,1,2)\n",
    "        G_scale = np.sum(G_y*norm_x, axis=axis)\n",
    "        G_shift = np.sum(G_y, axis=axis)\n",
    "        G_y = G_y * pm['scale']\n",
    "        pm['scale'] -= self.learning_rate * G_scale\n",
    "        pm['shift'] -= self.learning_rate * G_shift\n",
    "    G_input = G_y / std\n",
    "    return G_input\n",
    "    \n",
    "CnnRegModel.alloc_batch_normal_layer = cnn_reg_alloc_batch_normal_layer\n",
    "CnnRegModel.forward_batch_normal_layer = cnn_reg_forward_batch_normal_layer\n",
    "CnnRegModel.backprop_batch_normal_layer = cnn_reg_backprop_batch_normal_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
