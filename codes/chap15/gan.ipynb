{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../chap14/encoder_decoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan(RnnExtModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_init_parameters(self, hconfigs):\n",
    "    gconf = hconfigs['generator']\n",
    "    dconf = hconfigs['discriminor']\n",
    "\n",
    "    if not isinstance(gconf[0], list): gconf = [gconf]\n",
    "    if not isinstance(dconf[0], list): dconf = [dconf]\n",
    "        \n",
    "    self.seed_shape = hconfigs['seed_shape']\n",
    "    input_shape = self.dataset.input_shape\n",
    "\n",
    "    pmg, gen_shape = self.build_subnet(gconf, self.seed_shape)\n",
    "    pmd, bin_shape = self.build_subnet(dconf, input_shape)\n",
    "\n",
    "    assert tuple(gen_shape) == tuple(input_shape)\n",
    "    assert tuple(bin_shape) == tuple([1])\n",
    "    \n",
    "    self.gconfigs, self.dconfigs = gconf, dconf\n",
    "    self.pm_gen, self.pm_dis = pmg, pmd\n",
    "\n",
    "    self.seqout = False\n",
    "    self.pm_output = None\n",
    "    \n",
    "Gan.build_subnet = autoencoder_build_subnet\n",
    "Gan.init_parameters = gan_init_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train_step(self, x, y):\n",
    "    self.is_training = True\n",
    "    \n",
    "    d_loss = self.train_discriminor(x)\n",
    "    g_loss = self.train_generator(len(x))\n",
    "    \n",
    "    self.is_training = False\n",
    "    \n",
    "    return [d_loss, g_loss], 0\n",
    "\n",
    "Gan.train_step = gan_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train_discriminor(self, real_x):\n",
    "    mb_size = len(real_x)\n",
    "    \n",
    "    fake_x, _ = self.forward_generator(mb_size)\n",
    "\n",
    "    mixed_x = np.vstack([real_x, fake_x])\n",
    "    output, aux_dis = self.forward_discriminor(mixed_x)\n",
    "\n",
    "    y = np.zeros([2*mb_size, 1])\n",
    "    y[0:mb_size, 0] = 1.0\n",
    "    \n",
    "    d_loss, aux_pp = self.forward_postproc(output, y)\n",
    "    \n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "    self.backprop_discriminor(G_output, aux_dis)\n",
    "    \n",
    "    return d_loss\n",
    "\n",
    "Gan.train_discriminor = gan_train_discriminor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train_generator(self, mb_size):\n",
    "    fake_x, aux_gen = self.forward_generator(mb_size)\n",
    "\n",
    "    output, aux_dis = self.forward_discriminor(fake_x)\n",
    "    y = np.ones([mb_size, 1])\n",
    "    \n",
    "    g_loss, aux_pp = self.forward_postproc(output, y)\n",
    "\n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "\n",
    "    self.is_training = False\n",
    "    G_fake_x = self.backprop_discriminor(G_output, aux_dis)\n",
    "    self.is_training = True\n",
    "    self.backprop_generator(G_fake_x, aux_gen)\n",
    "    \n",
    "    return g_loss\n",
    "\n",
    "Gan.train_generator = gan_train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_forward_discriminor(self, x):\n",
    "    hidden = x\n",
    "    aux_dis = []\n",
    "\n",
    "    for n, hconfig in enumerate(self.dconfigs):\n",
    "        hidden, aux = self.forward_layer(hidden, hconfig, self.pm_dis[n])\n",
    "        aux_dis.append(aux)\n",
    "\n",
    "    return hidden, aux_dis\n",
    "\n",
    "def gan_backprop_discriminor(self, G_hidden, aux_dis):\n",
    "    for n in reversed(range(len(self.dconfigs))):\n",
    "        hconfig, pm, aux = self.dconfigs[n], self.pm_dis[n], aux_dis[n]\n",
    "        G_hidden = self.backprop_layer(G_hidden, hconfig, pm, aux)\n",
    "    return G_hidden\n",
    "\n",
    "\n",
    "Gan.forward_discriminor = gan_forward_discriminor\n",
    "Gan.backprop_discriminor = gan_backprop_discriminor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_forward_generator(self, mb_size):\n",
    "    hidden = np.random.uniform(-1.0, 1.0, size=[mb_size]+self.seed_shape)\n",
    "    aux_gen = []\n",
    "\n",
    "    for n, hconfig in enumerate(self.gconfigs):\n",
    "        hidden, aux = self.forward_layer(hidden, hconfig, self.pm_gen[n])\n",
    "        aux_gen.append(aux)\n",
    "\n",
    "    return hidden, aux_gen\n",
    "\n",
    "def gan_backprop_generator(self, G_hidden, aux_gen):\n",
    "    for n in reversed(range(len(self.gconfigs))):\n",
    "        hconfig, pm, aux = self.gconfigs[n], self.pm_gen[n], aux_gen[n]\n",
    "        G_hidden = self.backprop_layer(G_hidden, hconfig, pm, aux)\n",
    "    return G_hidden\n",
    "\n",
    "Gan.forward_generator = gan_forward_generator\n",
    "Gan.backprop_generator = gan_backprop_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_update_param(self, pm, key, G_key):\n",
    "    if not self.is_training: return\n",
    "        \n",
    "    super(Gan, self).update_param(pm, key, G_key)\n",
    "    \n",
    "Gan.update_param = gan_update_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_eval_accuracy(self, real_x, y, output=None):\n",
    "    mb_size = len(real_x)\n",
    "\n",
    "    fake_x, _ = self.forward_generator(mb_size)\n",
    "    mixed_x = np.vstack([real_x, fake_x])\n",
    "    output, aux_dis = self.forward_discriminor(mixed_x)\n",
    "\n",
    "    y = np.zeros([2*mb_size, 1])\n",
    "    y[0:mb_size] = 1.0\n",
    "    d_acc = self.dataset.eval_accuracy(mixed_x, y, output)\n",
    "    \n",
    "    fake_x, _ = self.forward_generator(mb_size)\n",
    "    output, aux_dis = self.forward_discriminor(fake_x)\n",
    "\n",
    "    y = np.ones([mb_size, 1])\n",
    "    g_acc = self.dataset.eval_accuracy(fake_x, y, output)\n",
    "    \n",
    "    return [d_acc, g_acc]\n",
    "\n",
    "Gan.eval_accuracy = gan_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_visualize(self, num):\n",
    "    real_x, _ = self.dataset.get_visualize_data(num)\n",
    "    fake_x, _ = self.forward_generator(num)\n",
    "    self.dataset.visualize(np.vstack([real_x,fake_x]))\n",
    "\n",
    "Gan.visualize = gan_visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
