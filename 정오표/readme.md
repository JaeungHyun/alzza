# 초판 1쇄 오탈자 수정표

오탈자에 대한 소중한 제보를 기다립니다. <br/>
저자에게 이메일(dhyoon1225@gmail.com) 주시면 
확인 후 여기 소개하고 책 개정에 반영하겠습니다.
## 39쪽 6째 줄
발견자: 코난아카데미<br/>
등록일: 2019.8.5<br/>
일부 테이터의 경우 → 일부 데이터의 경우

## 40쪽 그림
발견자: 박미선<br/>
등록일: 2019.7.17<br/>
축삭 (2번 나타난 것 중 왼쪽) → 세포체<br/>
가지돌기 → 축삭말단

## 41쪽 9째줄
발견자: 박미선<br/>
등록일: 2019.7.17<br/>
무수히 붙은 가지돌기를 → 무수히 붙은 축삭말단을

## 42쪽 그림 아래 4째줄
발견자: 박미선<br/>
등록일: 2019.7.17<br/>
각 수상돌기로부터 들어오는 → 각 가지돌기로부터 들어오는

## 51쪽 마지막줄
발견자: 윤덕호<br/>
등록일: 2019.8.30<br/>
3장에서 살펴본다 → 4장에서 살펴본다

## 55쪽 그림
발견자: 윤영섬<br/>
등록일: 2019.7.13<br/>
너 올해 몇 살이나? → 너 올해 몇 살이니?

## 61쪽 2째 줄
발견자: 박범진<br/>
등록일: 2019.7.28<br/>
몸시 어렵지만 → 몹시 어렵지만

## 70쪽 그림
발견자: 양승현<br/>
등록일: 2019.8.6<br/>
abablone_exec() → abalone_exec()

## 71쪽 1.10.3 코드 아래 설명문 첫 줄
발견자: 박범진<br/>
등록일: 2019.7.28<br/>
load_ablone_dataset() → load_abalone_dataset()

## 78쪽 3째 줄
발견자: 류기윤<br/>
등록일: 2019.8.22<br/>
순전파 첫 단계인 backprop_neuralnet() 함수가 → backprop_neuralnet() 함수가

## 78쪽 1.10.9절 첫 줄
발견자: 이인혁<br/>
등록일: 2019.8.29<br/>
신경만 → 신경망

## 94쪽 그림 오른쪽 맨 아래 말풍선
발견자: 박범진<br/>
등록일: 2019.7.31<br/>
0.270 → = 0.270

## 96쪽 글상자 4째 줄
발견자: 이상호<br/>
등록일: 2019.8.8<br/>
g(x)=1+e<sup>x</sup> → g(x)=1+e<sup>-x</sup>

## 2.6절 전체 (101쪽~102쪽 상단)
발견자: 윤덕호<br/>
등록일: 2019.9.5<br/>
전체적으로 P와 Q를 맞바꾸어야 99쪽 하단의 H(P,Q) 정의 내용과 혼동되지 않음

## 104쪽 글상자 안의 수식들
발견자: 류기윤<br/>
등록일: 2019.8.22<br/>
수식 두 번째 줄부터 4번째 줄까지 사이에 나타난 5개의 e<sup>-z</sup> → e<sup>-x</sup>

## 162쪽 코드상자 9째 줄
발견자: 이인혁<br/>
등록일: 2019.9.17<br/>
def backprop_neuralnet(G_output, x, learning_rate) → def backprop_neuralnet(G_output, x)

## 191쪽 코드상자 아래 본문 첫째 줄
발견자: 이인혁<br/>
등록일: 2019.9.24<br/>
exec_all() 메서드가  → 객체 초기화 메서드 __init__()가

## 191쪽 코드상자 아래 본문 3째 줄
발견자: 이인혁<br/>
등록일: 2019.9.24<br/>
init_model 함수와 → init_model_hiddens() 함수와

## 277쪽 3번째 수식 오른쪽
발견자: 서종우<br/>
등록일: 2019.8.7<br/>
dy<sub>k,i,j,ym</sub>x<sub>k,r-i+bh,c-j+bw,xm</sub> → dy<sub>k,i,j,ym</sub>x<sub>k,r+i-bh,c+j-bw,xm</sub>

## 345쪽 코드 8~13째 줄
발견자: 윤덕호<br/>
등록일: 2019.9.9<br/>
이어서 순전파 처리를 담당하는 forward_dropout_layer() 메서드에서는 ➍에서 np.random.binomial() 함수를 이용하여 pm['keep_prob']의 확률로 1, 나머지 확률로 0의 난수들을 x와 같은 형태로 발생시키고 ➎에서 이렇게 생성된 dmask를 x에 곱해 일부 원소들을 0으로 만들어 이후의 의사 결정 과정에서 배제하도록 한다. 이 처리는 학습 단계에서만 수행되어야 하므로 is_training 플래그를 검사하며, pm['keep_prob']로 나누어 기댓값을 유지시키고 dmask를 역전파용 보조 정보로 전달한다.<br/>
		→<br/>
➍의 순전파 처리에서는 pm['keep_prob']의 확률로 1, 나머지를 0으로 x와 같은 형태의 난수들을 발생시켜 드롭아웃 마스크를 만들고 ➎에서 이 마스크를 x에 곱해 일부 원소들을 0으로 만들어 이후의 처리 과정에서 배제시킨다. 그런데 ➍의 마스크는 x.shape 대신 x.shape[1:] 형태로 지정해 미니배치 단위로 일괄 처리하는 편이 더욱 효과적인데 이 점은 각자 확인해보기로 하자. 한편 드롭아웃 처리는 학습 단계에서만 수행되어야 하므로 is_training 플래그를 검사하며, pm['keep_prob']로 나누어 기댓값을 유지시킨다.<br/><br/>
* x.shape 대신 x.shape[1:] 형태로 지정하는 것이 올바른 드롭아웃 사용법이다. 하지만 이 부분을 수정할 경우 드롭아웃 실험부터의 모든 실험 결과가 교재로 달라지므로 개정판이 나올 때까지 코드 내용은 x.shape 형태를 이용하는 것으로 유지하기로 한다. x.shape[1:] 형태를 이용하는 실험은 각자 수행해 보기로 하자.

## 548쪽 8째 줄
발견자: 서종우<br/>
등록일: 2019.9.17<br/>
\[90, 120, 30\] → \[90, 120, 3\]

## 548쪽 9째 줄
발견자: 서종우<br/>
등록일: 2019.9.17<br/>
\[90, 120, 30\] → \[90, 120, 3\]
